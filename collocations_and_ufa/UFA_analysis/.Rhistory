message("Extracted from folder: ", folder_name)
message("Window size: ", window)
return(list(
start_year = start_year,
end_year = end_year,
window = window,
word_count = word_count
))
}
# Function to process individual collocate files
process_file <- function(file_path) {
year <- as.numeric(str_extract(basename(file_path), "\\d{4}"))
lines <- readLines(file_path)
if (length(grep("^\\d+\\s+\\w+", lines)) == 0) {
return(data.frame(word = character(), mi_score = numeric(), year = numeric()))
}
collocates_data <- lines[grep("^\\d+\\s+\\w+", lines)]
collocates <- lapply(collocates_data, function(line) {
parts <- strsplit(line, "\\s+")[[1]]
list(
word = parts[2],
mi_score = as.numeric(parts[7])
)
})
df <- do.call(rbind, lapply(collocates, as.data.frame))
df$year <- year
return(df)
}
# Load and filter collocate data
load_collocate_data <- function(data_dir, mi_score_threshold = 3) {
collocate_files <- fs::dir_ls(data_dir, regexp = "\\.txt$")
all_data <- do.call(rbind, lapply(collocate_files, process_file))
all_data <- all_data %>%
distinct(word, year, .keep_all = TRUE) %>%
filter(mi_score >= mi_score_threshold) %>%
mutate(present = 1)
return(all_data)
}
# Remaining helper functions
prepare_spread_data <- function(all_data) {
spread_data <- all_data %>%
pivot_wider(names_from = year, values_from = present, values_fill = 0)
return(spread_data)
}
save_spread_data <- function(spread_data, base_filename, output_dir = ".") {
output_file <- file.path(output_dir, paste0(base_filename, ".csv"))
write.table(spread_data, file = output_file, sep = "\t")
}
calculate_gwet_ac1 <- function(data) {
print(data)
i <- 3 # Skipping the first two columns (collocate and mi score)
v <- c()
years <- c()
while (i + 1 < ncol(data)) {
if (sum(colSums(data[, i:(i+2)]) > 0) >= 1) {
n <- gwet.ac1.raw(data[, i:(i+2)])$est$coeff.val
v <- c(v, n)
years <- c(years, as.numeric(colnames(data)[i]))
} else {
message("Skipping AC1 calculation for years ", colnames(data)[i], "-", colnames(data)[i+2], " due to insufficient data")
}
i <- i + 1
}
return(data.frame(year = years, ac1 = v))  # Return a data frame with the years and ac1 values
}
create_ufa_plot <- function(g, base_filename, output_dir = ".", target_word, window_type) {
output_file <- file.path(output_dir, paste0(base_filename, "_ufa.png"))
# Validate input data
if (nrow(g) == 0 || !all(c("year", "ac1") %in% names(g))) {
stop("Invalid or empty data provided to create_ufa_plot")
}
# Ensure numeric values
g$year <- as.numeric(g$year)
g$ac1 <- as.numeric(g$ac1)
# Remove any NA values
g <- g[complete.cases(g), ]
if (nrow(g) == 0) {
stop("No valid data points after cleaning")
}
# Calculate proper breaks and limits
min_year <- floor(min(g$year, na.rm = TRUE))
max_year <- ceiling(max(g$year, na.rm = TRUE))
break_seq <- seq(min_year, max_year, by = 20)
# Ensure the last year is included if it's not already in the sequence
if (max_year > max(break_seq)) {
break_seq <- c(break_seq, max_year)
}
p <- ggplot(g, aes(x = year, y = ac1)) +
geom_point() +
scale_x_continuous(
breaks = break_seq,
limits = c(min_year, max_year),
expand = expansion(mult = 0.02)  # Add small padding
) +
xlab("Year") +
ylab("AC1") +
ggtitle(
bquote(
"Results of UFA for " * italic(.(target_word)) *
": 3a-MI(3), " * .(window_type) * "L-" * .(window_type) * "R, " *
"C3"[relative] * "-" *
"NC3"[relative]
)
)
final_plot <- p +
stat_smooth(method = "gam",
formula = y ~ s(x, bs = "cr", fx = FALSE, k = 10),
size = 1, fill = "#707070", level = 0.95) +
stat_smooth(method = "gam",
formula = y ~ s(x, bs = "cr", fx = FALSE, k = 10),
size = 1, fill = "#FFFF00", level = 0.995) +
theme_minimal(base_size = 15) +
theme(
panel.background = element_rect(fill = "white"),
plot.background = element_rect(fill = "white"),
axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(margin = margin(b = 10)),
axis.title.x = element_text(margin = margin(t = 10)),
axis.title.y = element_text(margin = margin(r = 10))
)
ggsave(output_file, plot = final_plot, width = 12, height = 8, units = "in", dpi = 300)
}
#3 word windows
# results1 <- process_collocate_folder(
#   folder_path = "../collocation_results/FACT/collocate_results_1665-1958_FACT_css3_w3/collocation_txt",
#   output_dir = "collocate_results/3window"
# )
#
# results2 <- process_collocate_folder(
#   folder_path = "../collocation_results/FACTS/collocate_results_1665-1958_FACTS_css3_w3/collocation_txt",
#   output_dir = "collocate_results/3window"
# )
#5 word windows
results3 <- process_collocate_folder(
folder_path = "../collocation_results/FACT/collocate_results_1665-1958_FACT_css3_w5/collocation_txt",
output_dir = "collocate_results/5window"
)
#this is old, css=3
results4 <- process_collocate_folder(
folder_path = "../collocation_results/FACTS/collocate_results_1665-1958_FACTS_css3_w5/collocation_txt",
output_dir = "collocate_results/5window"
)
#5 word window latest (2 scaling for facts); too many? its certainly a choice not to use this one but they dont differ in the UFA plot all that much anyway
# results4 <- process_collocate_folder(
#   folder_path = "../collocation_results/FACTS/collocate_results_1665-1958_FACTS_css2_w5/collocation_txt",
#   output_dir = "collocate_results/5window"
# )
#3l3r
library(knitr)
folder_to_ignore <- c("5window", "old/5window", "old/3window")
files <- list.files("collocate_results/",
pattern = "_ufa\\.png$",
full.names = TRUE,
recursive = TRUE)
files <- files[!grepl(paste(folder_to_ignore, collapse = "|"), files) & grepl("3window", files)]
if (length(files) == 0) {
print("No images found with '_ufa.png' in the filename.")
} else {
include_graphics(files)
}
#5l5r
folder_to_ignore <- c("3window", "old/5window", "old/3window")
files <- list.files("collocate_results/",
pattern = "_ufa\\.png$",
full.names = TRUE,
recursive = TRUE)
files <- files[!grepl(paste(folder_to_ignore, collapse = "|"), files) & grepl("5window", files)]
# Check if there are files left, then plot or print a message
if (length(files) == 0) {
print("No images found with '_ufa.png' in the filename.")
} else {
include_graphics(files)
}
library(dplyr)
library(tidyr)
create_collocate_table <- function(results, target_word = "fact") {
collocate_table <- results$all_data %>%
filter(mi_score >= 3) %>%  # Filter for MI scores >= 3
arrange(year) %>%  # Sort by MI score first, then year
select(Year = year,
Collocate = word,
`MI Score` = mi_score) %>%
as_tibble()
return(collocate_table)
}
#fact
#r1 = create_collocate_table(results1) #fact 3L3R
r3= create_collocate_table(results3) #fact 5L5R
#facts
#r2 = create_collocate_table(results2) #facts 3L3R
r4 = create_collocate_table(results4) #facts 5L5R
#r1
r3
#r2
r4
#write.csv(r1, "collocate_results/dfs/fact3.csv")
write.csv(r3, "collocate_results/dfs/fact5.csv")
#write.csv(r2, "collocate_results/dfs/facts3.csv")
write.csv(r4, "collocate_results/dfs/facts5.csv")
#from claude, just for funsies (illustrates how few words are used for facts)
library(dplyr)
library(tidyr)
library(ggplot2)
# Function to count unique collocates per year for each dataset
analyze_unique_collocates <- function(results_list, labels) {
# Create a list to store counts for each dataset
yearly_counts <- list()
for(i in seq_along(results_list)) {
counts <- results_list[[i]] %>%
group_by(Year) %>%
summarize(unique_words = n_distinct(Collocate)) %>%
mutate(dataset = labels[i])
yearly_counts[[i]] <- counts
}
# Combine all counts
all_counts <- bind_rows(yearly_counts)
# Create visualization
ggplot(all_counts, aes(x = Year, y = unique_words, color = dataset)) +
geom_line(size = 1) +
geom_point() +
theme_minimal() +
labs(title = "Unique Collocates Over Time",
subtitle = "Comparison across different window sizes",
y = "Number of Unique Collocates",
color = "Dataset") +
theme(legend.position = "bottom",
plot.title = element_text(face = "bold"),
axis.title = element_text(face = "bold"))
}
# Create list of your results
results_list <- list(
#create_collocate_table(results1),
#create_collocate_table(results2),
create_collocate_table(results3),
create_collocate_table(results4)
)
# Labels for each dataset
labels <- c("fact 3L3R", "facts 3L3R", "fact 5L5R", "facts 5L5R")
# Generate the visualization
analyze_unique_collocates(results_list, labels)
# Print summary statistics
for(i in seq_along(results_list)) {
cat("\nSummary for", labels[i], ":\n")
print(summary(results_list[[i]] %>%
group_by(Year) %>%
summarize(unique_words = n_distinct(Collocate)) %>%
pull(unique_words)))
}
#from claude, just for funsies (illustrates how few words are used for facts)
library(dplyr)
library(tidyr)
library(ggplot2)
# Function to count unique collocates per year for each dataset
analyze_unique_collocates <- function(results_list, labels) {
# Create a list to store counts for each dataset
yearly_counts <- list()
for(i in seq_along(results_list)) {
counts <- results_list[[i]] %>%
group_by(Year) %>%
summarize(unique_words = n_distinct(Collocate)) %>%
mutate(dataset = labels[i])
yearly_counts[[i]] <- counts
}
# Combine all counts
all_counts <- bind_rows(yearly_counts)
# Create visualization
ggplot(all_counts, aes(x = Year, y = unique_words, color = dataset)) +
geom_line(size = 1) +
knitr::opts_chunk$set(echo = TRUE)
#code from lancaster, somehow mine might differ a bit?
#Calculate Gwet's AC1; b...input data frame
#i = 1; v <- c(); while(i+1 < ncol(b)) {n=(gwet.ac1.raw(b[,i:(i+2)])[3]);v<- c(v, n); i= i+1; }
#Prepare data frame
#h<-seq(from, to, by = 1); g<-data.frame(h,v)
#Produce graph
#p<-ggplot(g, aes(x = g[,1], y =g[,2])) + xlim(from, to)+ scale_x_continuous(breaks = seq(from, to, by = 10)) + geom_point()  + xlab("Time") + ylab("AC1"); p + stat_smooth(method = "gam", formula = y ~ s(x, bs = "cr", fx=FALSE, k =10), size = 1, fill="#707070", level = 0.95 )+ stat_smooth(method = "gam", formula = y ~ s(x, bs = "cr", fx=FALSE, k =10), size = 1, fill="#FFFF00", level = 0.99)
#trying to figure out the exact right way to do gwet ac based on the example so theres no or less mistakes there
# #current ver
# calculate_gwet_ac1 <- function(data) {
#   print(data)
#   i <- 3 # Skipping the first two columns (collocate and mi score)
#   v <- c()
#   years <- c()
#
#   while (i + 1 < ncol(data)) { # Make sure to avoid out-of-bounds access
#     if (sum(colSums(data[, i:(i+2)]) > 0) >= 1) {
#       n <- gwet.ac1.raw(data[, i:(i+2)])$est$coeff.val
#       v <- c(v, n)
#       years <- c(years, as.numeric(colnames(data)[i]))
#     } else {
#       message("Skipping AC1 calculation for years ", colnames(data)[i], "-", colnames(data)[i+2], " due to insufficient data")
#     }
#     i <- i + 1
#   }
#
#   return(data.frame(year = years, ac1 = v))  # Return a data frame with the years and ac1 values
# }
# #old ver
# calculate_gwet_ac1 <- function(data) {
#   i <- 3
#   v <- c()
#   years <- c()
#
#   while (i <= ncol(data) - 1) {
#     if (sum(colSums(data[, i:(i+1)]) > 0) >= 1) {
#       n <- gwet.ac1.raw(data[, i:(i+1)])$est$coeff.val
#       v <- c(v, n)
#       years <- c(years, as.numeric(colnames(data)[i]))
#     } else {
#       message("Skipping AC1 calculation for years ", colnames(data)[i], "-", colnames(data)[i+1], " due to insufficient data")
#     }
#     i <- i + 1
#   }
#
#   return(data.frame(year = years, ac1 = v))
# }
library(fs)
library(tidyverse)
library(irrCAC)
library(pacman)
# Main function to process a single folder of collocate data
process_collocate_folder <- function(folder_path,
mi_score_threshold = 3,
output_dir = ".") {
folder_info <- extract_folder_info(folder_path)
dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)
target_word <- ifelse(grepl("FACTS", folder_path), "facts",
ifelse(grepl("FACT", folder_path), "fact", "unknown"))
window = folder_info$window
all_data <- load_collocate_data(folder_path, mi_score_threshold)
spread_data <- prepare_spread_data(all_data)
output_file_base <- paste0(target_word, "_collocates_",
folder_info$start_year, "_",
folder_info$end_year,
folder_info$window, "")
save_spread_data(spread_data, output_file_base, output_dir)
# Calculate Gwet's AC1
g <- calculate_gwet_ac1(spread_data)
create_ufa_plot(g, output_file_base, output_dir, target_word, window)
return(list(
all_data = all_data,
spread_data = spread_data,
gwet_ac1 = g,
folder_info = folder_info
))
}
# Helper function to extract information from folder name
extract_folder_info <- function(folder_path) {
# Get the parent folder name instead of just the last directory
folder_name <- basename(dirname(folder_path))
year_range <- str_extract(folder_name, "\\d{4}-\\d{4}")
if (!is.na(year_range)) {
years <- strsplit(year_range, "-")[[1]]
start_year <- years[1]
end_year <- years[2]
} else {
warning("Could not find year range in folder name: ", folder_name)
start_year <- "UNKNOWN"
end_year <- "UNKNOWN"
}
# Fixed window pattern to correctly extract the number after 'w'
window <- str_extract(folder_name, "w\\d")
if (is.na(window)) {
warning("Could not find window size in folder name: ", folder_name)
window <- "3"  # Default to 3 if not found
} else {
window <- substr(window, 2, 2)  # Extract just the number
}
# Update word count extraction to handle both formats
word_count <- ifelse(
grepl("css", folder_name),
"css",
str_extract(folder_name, "\\d+[-_]\\d+")
)
# Add some debugging output
message("Extracted from folder: ", folder_name)
message("Window size: ", window)
return(list(
start_year = start_year,
end_year = end_year,
window = window,
word_count = word_count
))
}
# Function to process individual collocate files
process_file <- function(file_path) {
year <- as.numeric(str_extract(basename(file_path), "\\d{4}"))
lines <- readLines(file_path)
if (length(grep("^\\d+\\s+\\w+", lines)) == 0) {
return(data.frame(word = character(), mi_score = numeric(), year = numeric()))
}
collocates_data <- lines[grep("^\\d+\\s+\\w+", lines)]
collocates <- lapply(collocates_data, function(line) {
parts <- strsplit(line, "\\s+")[[1]]
list(
word = parts[2],
mi_score = as.numeric(parts[7])
)
})
df <- do.call(rbind, lapply(collocates, as.data.frame))
df$year <- year
return(df)
}
# Load and filter collocate data
load_collocate_data <- function(data_dir, mi_score_threshold = 3) {
collocate_files <- fs::dir_ls(data_dir, regexp = "\\.txt$")
all_data <- do.call(rbind, lapply(collocate_files, process_file))
all_data <- all_data %>%
distinct(word, year, .keep_all = TRUE) %>%
filter(mi_score >= mi_score_threshold) %>%
mutate(present = 1)
return(all_data)
}
# Remaining helper functions
prepare_spread_data <- function(all_data) {
spread_data <- all_data %>%
pivot_wider(names_from = year, values_from = present, values_fill = 0)
return(spread_data)
}
save_spread_data <- function(spread_data, base_filename, output_dir = ".") {
output_file <- file.path(output_dir, paste0(base_filename, ".csv"))
write.table(spread_data, file = output_file, sep = "\t")
}
calculate_gwet_ac1 <- function(data) {
print(data)
i <- 3 # Skipping the first two columns (collocate and mi score)
v <- c()
years <- c()
while (i + 1 < ncol(data)) {
if (sum(colSums(data[, i:(i+2)]) > 0) >= 1) {
n <- gwet.ac1.raw(data[, i:(i+2)])$est$coeff.val
v <- c(v, n)
years <- c(years, as.numeric(colnames(data)[i]))
} else {
message("Skipping AC1 calculation for years ", colnames(data)[i], "-", colnames(data)[i+2], " due to insufficient data")
}
i <- i + 1
}
return(data.frame(year = years, ac1 = v))  # Return a data frame with the years and ac1 values
}
create_ufa_plot <- function(g, base_filename, output_dir = ".", target_word, window_type) {
output_file <- file.path(output_dir, paste0(base_filename, "_ufa.png"))
# Validate input data
if (nrow(g) == 0 || !all(c("year", "ac1") %in% names(g))) {
stop("Invalid or empty data provided to create_ufa_plot")
}
# Ensure numeric values
g$year <- as.numeric(g$year)
g$ac1 <- as.numeric(g$ac1)
# Remove any NA values
g <- g[complete.cases(g), ]
if (nrow(g) == 0) {
stop("No valid data points after cleaning")
}
# Calculate proper breaks and limits
min_year <- floor(min(g$year, na.rm = TRUE))
max_year <- ceiling(max(g$year, na.rm = TRUE))
break_seq <- seq(min_year, max_year, by = 20)
# Ensure the last year is included if it's not already in the sequence
if (max_year > max(break_seq)) {
break_seq <- c(break_seq, max_year)
}
p <- ggplot(g, aes(x = year, y = ac1)) +
geom_point() +
scale_x_continuous(
breaks = break_seq,
limits = c(min_year, max_year),
expand = expansion(mult = 0.02)  # Add small padding
) +
xlab("Year") +
ylab("AC1") +
ggtitle(
bquote(
"Results of UFA for " * italic(.(target_word)) *
": 3a-MI(3), " * .(window_type) * "L-" * .(window_type) * "R, " *
"C3"[relative] * "-" *
"NC3"[relative]
)
)
final_plot <- p +
stat_smooth(method = "gam",
formula = y ~ s(x, bs = "cr", fx = FALSE, k = 10),
size = 1, fill = "#707070", level = 0.95) +
stat_smooth(method = "gam",
formula = y ~ s(x, bs = "cr", fx = FALSE, k = 10),
size = 1, fill = "#FFFF00", level = 0.995) +
theme_minimal(base_size = 15) +
theme(
panel.background = element_rect(fill = "white"),
plot.background = element_rect(fill = "white"),
axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(margin = margin(b = 10)),
axis.title.x = element_text(margin = margin(t = 10)),
axis.title.y = element_text(margin = margin(r = 10))
)
ggsave(output_file, plot = final_plot, width = 12, height = 8, units = "in", dpi = 300)
}
#3 word windows
# results1 <- process_collocate_folder(
#   folder_path = "../collocation_results/FACT/collocate_results_1665-1958_FACT_css3_w3/collocation_txt",
#   output_dir = "collocate_results/3window"
# )
#
# results2 <- process_collocate_folder(
#   folder_path = "../collocation_results/FACTS/collocate_results_1665-1958_FACTS_css3_w3/collocation_txt",
#   output_dir = "collocate_results/3window"
# )
#5 word windows
results3 <- process_collocate_folder(
folder_path = "../collocation_results/FACT/collocate_results_1665-1958_FACT_css3_w5/collocation_txt",
output_dir = "collocate_results/5window"
)
